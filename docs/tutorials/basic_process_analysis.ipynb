{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Process Analysis with Heraclitus\n",
    "\n",
    "This tutorial demonstrates how to use Heraclitus for basic process mining and analysis tasks.\n",
    "\n",
    "## 1. Introduction to Process Mining\n",
    "\n",
    "Process mining is a research discipline that sits between machine learning and data mining on one side, and process modeling and analysis on the other. It aims to discover, monitor, and improve real processes by extracting knowledge from event logs readily available in today's information systems.\n",
    "\n",
    "Heraclitus provides tools for process mining, including:\n",
    "- Event log management\n",
    "- Process discovery\n",
    "- Process visualization\n",
    "- Performance analysis\n",
    "- Statistical comparison\n",
    "\n",
    "Let's get started by installing Heraclitus (if you haven't already):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Heraclitus\n",
    "!pip install heraclitus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating and Loading Event Logs\n",
    "\n",
    "The fundamental data structure in process mining is the **event log**. An event log contains events related to cases (process instances). Each event has at least a case ID, an activity name, and usually a timestamp.\n",
    "\n",
    "Let's create a sample event log for demonstration purposes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Create sample data\n",
    "cases = []\n",
    "\n",
    "# Process model: Register -> Review -> (Approve or Reject) -> Notify\n",
    "# We'll create 50 cases\n",
    "\n",
    "for i in range(1, 51):\n",
    "    case_id = f\"case_{i}\"\n",
    "    \n",
    "    # Standard path (70%)\n",
    "    if i <= 35:\n",
    "        start_time = datetime(2023, 1, 1) + timedelta(days=i, hours=np.random.randint(0, 5))\n",
    "        \n",
    "        # Register\n",
    "        events = [\n",
    "            {\n",
    "                \"case_id\": case_id,\n",
    "                \"activity\": \"Register\",\n",
    "                \"timestamp\": start_time,\n",
    "                \"resource\": f\"employee_{np.random.randint(1, 5)}\"\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        # Review\n",
    "        events.append({\n",
    "            \"case_id\": case_id,\n",
    "            \"activity\": \"Review\",\n",
    "            \"timestamp\": start_time + timedelta(hours=np.random.randint(1, 4)),\n",
    "            \"resource\": f\"employee_{np.random.randint(1, 5)}\"\n",
    "        })\n",
    "        \n",
    "        # Approve or Reject (80% approve, 20% reject)\n",
    "        if i <= 28:  # 80% of 35 cases\n",
    "            events.append({\n",
    "                \"case_id\": case_id,\n",
    "                \"activity\": \"Approve\",\n",
    "                \"timestamp\": events[-1][\"timestamp\"] + timedelta(hours=np.random.randint(1, 3)),\n",
    "                \"resource\": f\"employee_{np.random.randint(1, 5)}\"\n",
    "            })\n",
    "        else:\n",
    "            events.append({\n",
    "                \"case_id\": case_id,\n",
    "                \"activity\": \"Reject\",\n",
    "                \"timestamp\": events[-1][\"timestamp\"] + timedelta(hours=np.random.randint(1, 3)),\n",
    "                \"resource\": f\"employee_{np.random.randint(1, 5)}\"\n",
    "            })\n",
    "        \n",
    "        # Notify\n",
    "        events.append({\n",
    "            \"case_id\": case_id,\n",
    "            \"activity\": \"Notify\",\n",
    "            \"timestamp\": events[-1][\"timestamp\"] + timedelta(hours=np.random.randint(1, 2)),\n",
    "            \"resource\": f\"employee_{np.random.randint(1, 5)}\"\n",
    "        })\n",
    "    \n",
    "    # Variation 1: Register -> Verify -> Review -> (Approve or Reject) -> Notify (30%)\n",
    "    else:\n",
    "        start_time = datetime(2023, 1, 1) + timedelta(days=i, hours=np.random.randint(0, 5))\n",
    "        \n",
    "        # Register\n",
    "        events = [\n",
    "            {\n",
    "                \"case_id\": case_id,\n",
    "                \"activity\": \"Register\",\n",
    "                \"timestamp\": start_time,\n",
    "                \"resource\": f\"employee_{np.random.randint(1, 5)}\"\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        # Verify (additional step)\n",
    "        events.append({\n",
    "            \"case_id\": case_id,\n",
    "            \"activity\": \"Verify\",\n",
    "            \"timestamp\": start_time + timedelta(hours=np.random.randint(1, 3)),\n",
    "            \"resource\": f\"employee_{np.random.randint(1, 5)}\"\n",
    "        })\n",
    "        \n",
    "        # Review\n",
    "        events.append({\n",
    "            \"case_id\": case_id,\n",
    "            \"activity\": \"Review\",\n",
    "            \"timestamp\": events[-1][\"timestamp\"] + timedelta(hours=np.random.randint(1, 4)),\n",
    "            \"resource\": f\"employee_{np.random.randint(1, 5)}\"\n",
    "        })\n",
    "        \n",
    "        # Approve or Reject (50% each)\n",
    "        if i <= 43:  # Roughly 50% of remaining cases\n",
    "            events.append({\n",
    "                \"case_id\": case_id,\n",
    "                \"activity\": \"Approve\",\n",
    "                \"timestamp\": events[-1][\"timestamp\"] + timedelta(hours=np.random.randint(1, 3)),\n",
    "                \"resource\": f\"employee_{np.random.randint(1, 5)}\"\n",
    "            })\n",
    "        else:\n",
    "            events.append({\n",
    "                \"case_id\": case_id,\n",
    "                \"activity\": \"Reject\",\n",
    "                \"timestamp\": events[-1][\"timestamp\"] + timedelta(hours=np.random.randint(1, 3)),\n",
    "                \"resource\": f\"employee_{np.random.randint(1, 5)}\"\n",
    "            })\n",
    "        \n",
    "        # Notify\n",
    "        events.append({\n",
    "            \"case_id\": case_id,\n",
    "            \"activity\": \"Notify\",\n",
    "            \"timestamp\": events[-1][\"timestamp\"] + timedelta(hours=np.random.randint(1, 2)),\n",
    "            \"resource\": f\"employee_{np.random.randint(1, 5)}\"\n",
    "        })\n",
    "    \n",
    "    cases.extend(events)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(cases)\n",
    "\n",
    "# Display the first few rows\n",
    "print(f\"Created {len(df)} events for {len(df['case_id'].unique())} cases\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our sample data, let's create an EventLog object using Heraclitus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heraclitus.data import EventLog\n",
    "\n",
    "# Create EventLog\n",
    "event_log = EventLog(\n",
    "    df,\n",
    "    case_id_column=\"case_id\",\n",
    "    activity_column=\"activity\",\n",
    "    timestamp_column=\"timestamp\"\n",
    ")\n",
    "\n",
    "# Basic information\n",
    "print(f\"Number of cases: {event_log.case_count()}\")\n",
    "print(f\"Number of events: {event_log.event_count()}\")\n",
    "print(f\"\\nUnique activities:\")\n",
    "for activity in event_log.get_activities():\n",
    "    print(f\"- {activity}\")\n",
    "    \n",
    "# Time range\n",
    "time_range = event_log.get_time_range()\n",
    "print(f\"\\nTime range: {time_range[0]} to {time_range[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Working with XES Files\n",
    "\n",
    "Event logs are often shared in XES format (eXtensible Event Stream), which is the IEEE 1849-2016 standard for process mining event logs.\n",
    "\n",
    "Heraclitus supports importing and exporting XES files. Let's export our event log to XES and then re-import it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "\n",
    "# Create a temporary file for the XES data\n",
    "temp_dir = tempfile.gettempdir()\n",
    "xes_file_path = os.path.join(temp_dir, \"sample_log.xes\")\n",
    "\n",
    "# Export to XES\n",
    "event_log.to_xes(xes_file_path)\n",
    "print(f\"Exported event log to: {xes_file_path}\")\n",
    "\n",
    "# Import from XES\n",
    "imported_log = EventLog.from_xes(xes_file_path)\n",
    "print(f\"\\nRe-imported event log from XES file:\")\n",
    "print(f\"Number of cases: {imported_log.case_count()}\")\n",
    "print(f\"Number of events: {imported_log.event_count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Basic Process Analysis\n",
    "\n",
    "Let's perform some basic analysis on our event log.\n",
    "\n",
    "### 3.1 Case Duration Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heraclitus.metrics import calculate_cycle_time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Calculate cycle time for all cases\n",
    "cycle_time_stats = calculate_cycle_time(event_log, unit=\"hours\", include_stats=True)\n",
    "print(f\"Cycle time statistics (hours):\")\n",
    "for key, value in cycle_time_stats.items():\n",
    "    print(f\"- {key}: {value:.2f}\")\n",
    "\n",
    "# Calculate cycle time for each case\n",
    "case_ids = event_log.get_case_ids()\n",
    "case_durations = []\n",
    "\n",
    "for case_id in case_ids:\n",
    "    duration = calculate_cycle_time(event_log, case_id=case_id, unit=\"hours\")\n",
    "    case_durations.append({\"case_id\": case_id, \"duration\": duration})\n",
    "\n",
    "durations_df = pd.DataFrame(case_durations)\n",
    "\n",
    "# Plot duration distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(durations_df[\"duration\"], kde=True)\n",
    "plt.title(\"Case Duration Distribution (hours)\")\n",
    "plt.xlabel(\"Duration (hours)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Activity Frequency Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activity frequency\n",
    "activity_counts = event_log.to_dataframe()[event_log.activity_column].value_counts()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=activity_counts.index, y=activity_counts.values)\n",
    "plt.title(\"Activity Frequency\")\n",
    "plt.xlabel(\"Activity\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Variant Analysis\n",
    "\n",
    "Let's analyze the different process variants in our event log. A variant is a unique sequence of activities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get variants\n",
    "variants = {}\n",
    "\n",
    "for case_id in case_ids:\n",
    "    case_df = event_log.filter_case(case_id)\n",
    "    activities = list(case_df[event_log.activity_column])\n",
    "    variant_key = \"->".join(activities)\n",
    "    \n",
    "    if variant_key in variants:\n",
    "        variants[variant_key][\"count\"] += 1\n",
    "        variants[variant_key][\"cases\"].append(case_id)\n",
    "    else:\n",
    "        variants[variant_key] = {\n",
    "            \"count\": 1,\n",
    "            \"sequence\": activities,\n",
    "            \"cases\": [case_id]\n",
    "        }\n",
    "\n",
    "# Sort variants by frequency\n",
    "sorted_variants = sorted(variants.items(), key=lambda x: x[1][\"count\"], reverse=True)\n",
    "\n",
    "# Display variants\n",
    "print(f\"Found {len(variants)} different process variants\")\n",
    "print(\"\\nTop variants:\")\n",
    "for i, (variant_key, variant_info) in enumerate(sorted_variants[:5], 1):\n",
    "    print(f\"Variant {i}: {variant_key}\")\n",
    "    print(f\"- Count: {variant_info['count']} cases ({variant_info['count']/len(case_ids)*100:.1f}%)\")\n",
    "    print(f\"- Example case: {variant_info['cases'][0]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Process Discovery\n",
    "\n",
    "Process discovery is a key component of process mining. Let's discover the process model using a Directly-Follows Graph (DFG)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heraclitus.discovery.process_discovery import discover_directly_follows_graph\n",
    "\n",
    "# Discover DFG\n",
    "dfg = discover_directly_follows_graph(event_log)\n",
    "\n",
    "# Print DFG information\n",
    "print(\"Directly-Follows Graph:\")\n",
    "print(f\"- Nodes (activities): {len(dfg.get_nodes())}\")\n",
    "print(f\"- Edges (transitions): {len(dfg.get_edges())}\")\n",
    "\n",
    "print(\"\\nStarting activities:\")\n",
    "for activity, count in dfg.get_starting_activities().items():\n",
    "    print(f\"- {activity}: {count} cases\")\n",
    "\n",
    "print(\"\\nEnding activities:\")\n",
    "for activity, count in dfg.get_ending_activities().items():\n",
    "    print(f\"- {activity}: {count} cases\")\n",
    "\n",
    "print(\"\\nTop transitions (activity -> activity):\")\n",
    "sorted_edges = sorted(dfg.get_edges().items(), key=lambda x: x[1], reverse=True)\n",
    "for (source, target), frequency in sorted_edges:\n",
    "    print(f\"- {source} -> {target}: {frequency} occurrences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Visualizing the Process Model\n",
    "\n",
    "Let's visualize the process model using Heraclitus's visualization capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heraclitus.visualization import create_interactive_process_map\n",
    "\n",
    "# Create and display an interactive process map\n",
    "fig = create_interactive_process_map(event_log)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Performance Analysis\n",
    "\n",
    "Now let's analyze the performance of different activities in our process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heraclitus.metrics import calculate_waiting_time, calculate_processing_time\n",
    "\n",
    "# Analyze waiting time for Review activity\n",
    "review_waiting = calculate_waiting_time(event_log, \"Review\", unit=\"hours\", include_stats=True)\n",
    "print(\"Waiting time for Review activity (hours):\")\n",
    "for key, value in review_waiting.items():\n",
    "    print(f\"- {key}: {value:.2f}\")\n",
    "\n",
    "# Analyze processing time for Review activity\n",
    "review_processing = calculate_processing_time(event_log, \"Review\", unit=\"hours\", include_stats=True)\n",
    "print(\"\\nProcessing time for Review activity (hours):\")\n",
    "for key, value in review_processing.items():\n",
    "    print(f\"- {key}: {value:.2f}\")\n",
    "\n",
    "# Compare waiting times across activities\n",
    "activities = [act for act in event_log.get_activities() if act != \"Notify\"]\n",
    "waiting_times = []\n",
    "\n",
    "for activity in activities:\n",
    "    try:\n",
    "        waiting = calculate_waiting_time(event_log, activity, unit=\"hours\", include_stats=True)\n",
    "        waiting_times.append({\n",
    "            \"activity\": activity,\n",
    "            \"mean\": waiting[\"mean\"],\n",
    "            \"median\": waiting[\"median\"],\n",
    "            \"std\": waiting[\"std\"]\n",
    "        })\n",
    "    except ValueError:\n",
    "        # Skip if no waiting times could be calculated (e.g., for the first activity)\n",
    "        pass\n",
    "\n",
    "waiting_df = pd.DataFrame(waiting_times)\n",
    "\n",
    "# Plot waiting times\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(waiting_df[\"activity\"], waiting_df[\"mean\"])\n",
    "plt.errorbar(waiting_df[\"activity\"], waiting_df[\"mean\"], yerr=waiting_df[\"std\"], fmt=\"o\", color=\"red\")\n",
    "plt.title(\"Average Waiting Time by Activity\")\n",
    "plt.xlabel(\"Activity\")\n",
    "plt.ylabel(\"Average Waiting Time (hours)\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Statistical Comparison\n",
    "\n",
    "Let's compare the performance between different process variants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heraclitus.statistics.comparison import compare_cycle_times\n",
    "\n",
    "# Filter cases by variant\n",
    "standard_cases = []\n",
    "verify_cases = []\n",
    "\n",
    "for case_id in case_ids:\n",
    "    case_df = event_log.filter_case(case_id)\n",
    "    activities = list(case_df[event_log.activity_column])\n",
    "    \n",
    "    if \"Verify\" in activities:\n",
    "        verify_cases.append(case_id)\n",
    "    else:\n",
    "        standard_cases.append(case_id)\n",
    "\n",
    "# Create filtered event logs\n",
    "standard_log = event_log.filter_cases(standard_cases)\n",
    "verify_log = event_log.filter_cases(verify_cases)\n",
    "\n",
    "print(f\"Standard variant: {len(standard_cases)} cases\")\n",
    "print(f\"Verify variant: {len(verify_cases)} cases\")\n",
    "\n",
    "# Compare cycle times\n",
    "comparison = compare_cycle_times(\n",
    "    standard_log,\n",
    "    verify_log,\n",
    "    unit=\"hours\",\n",
    "    label1=\"Standard Process\",\n",
    "    label2=\"Process with Verification\"\n",
    ")\n",
    "\n",
    "print(\"\\nCycle Time Comparison:\")\n",
    "print(f\"- Standard Process: {comparison['mean1']:.2f} hours\")\n",
    "print(f\"- Process with Verification: {comparison['mean2']:.2f} hours\")\n",
    "print(f\"- Difference: {comparison['difference']:.2f} hours\")\n",
    "print(f\"- p-value: {comparison['p_value']:.4f}\")\n",
    "print(f\"- Statistically significant: {'Yes' if comparison['p_value'] < 0.05 else 'No'}\")\n",
    "\n",
    "# Plot comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "standard_times = [calculate_cycle_time(standard_log, case_id=case_id, unit=\"hours\") for case_id in standard_cases]\n",
    "verify_times = [calculate_cycle_time(verify_log, case_id=case_id, unit=\"hours\") for case_id in verify_cases]\n",
    "\n",
    "plt.boxplot([standard_times, verify_times], labels=[\"Standard Process\", \"Process with Verification\"])\n",
    "plt.title(\"Cycle Time Comparison Between Process Variants\")\n",
    "plt.ylabel(\"Cycle Time (hours)\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conclusion\n",
    "\n",
    "In this tutorial, we've explored the basic functionality of Heraclitus for process mining and analysis:\n",
    "\n",
    "1. Creating and loading event logs\n",
    "2. Working with XES files\n",
    "3. Basic process analysis\n",
    "4. Process discovery and visualization\n",
    "5. Performance analysis\n",
    "6. Statistical comparison\n",
    "\n",
    "Heraclitus provides many more features for advanced process mining, including:\n",
    "- Machine learning and anomaly detection\n",
    "- Working with large datasets using DuckDB\n",
    "- Conformance checking\n",
    "- Advanced process discovery algorithms through PM4PY integration\n",
    "\n",
    "For more information, check out the other tutorials and examples in the Heraclitus documentation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}